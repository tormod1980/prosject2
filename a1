import numpy as np
import matplotlib.pyplot as plt

# Sample function: f(x) = a0 + a1*x + a2*x^2
def f(x, a0, a1, a2):
    """Compute the value of a quadratic function given coefficients."""
    return a0 + a1 * x + a2 * x**2

# Function to compute the analytical gradient
def gradient(X, y, weights):
    """
    Calculate the gradient of the loss function.
    
    Parameters:
        X (ndarray): Feature matrix (m x n), where m is the number of samples and n is the number of features.
        y (ndarray): Target values (m x 1).
        weights (ndarray): Current weights (n x 1).
        
    Returns:
        grad (ndarray): Gradient of the loss function with respect to the weights.
    """
    predictions = X @ weights  # Compute predictions
    errors = predictions - y    # Calculate the difference between predictions and actual values
    grad = (1 / len(y)) * (X.T @ errors)  # Compute the average gradient
    return grad

# Gradient Descent algorithm
def gradient_descent(X, y, learning_rate, num_iterations):
    """
    Perform gradient descent optimization to minimize the loss function.
    
    Parameters:
        X (ndarray): Feature matrix (m x n).
        y (ndarray): Target values (m x 1).
        learning_rate (float): Step size for updating weights.
        num_iterations (int): Number of iterations to perform.
        
    Returns:
        weights (ndarray): Final weights after optimization.
        loss_history (list): List of loss values recorded during each iteration.
    """
    weights = np.zeros(X.shape[1])  # Initialize weights to zero
    loss_history = []  # To track the loss over iterations

    for _ in range(num_iterations):
        grad = gradient(X, y, weights)  # Calculate the gradient
        weights -= learning_rate * grad  # Update weights
        # Compute the mean squared error loss
        loss = np.mean((X @ weights - y) ** 2)
        loss_history.append(loss)  # Record the loss

    return weights, loss_history

# Generate sample data
X = np.column_stack((np.ones(100), np.linspace(-3, 3, 100), np.linspace(-3, 3, 100)**2))
y = f(X[:, 1], 1, 2, 3) + np.random.normal(0, 0.5, 100)  # Add some noise to the target values

# Set hyperparameters for gradient descent
learning_rate = 0.01
num_iterations = 1000

# Perform gradient descent
weights, loss_history = gradient_descent(X, y, learning_rate, num_iterations)

# Plot the loss over iterations
plt.plot(loss_history)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Loss over Iterations')
plt.grid(True)  # Optional: add grid for better readability
plt.show()

